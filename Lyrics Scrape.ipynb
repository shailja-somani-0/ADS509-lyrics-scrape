{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95952cac",
   "metadata": {},
   "source": [
    "# ADS 509 Module 1: APIs and Web Scraping\n",
    "Shailja Somani\\\n",
    "ADS 509 Summer 2024\\\n",
    "May 13, 2024\n",
    "\n",
    "This notebook has two parts. In the first part, you will scrape lyrics from AZLyrics.com. In the second part, you'll run code that verifies the completeness of your data pull. \n",
    "\n",
    "For this assignment you have chosen two musical artists who have at least 20 songs with lyrics on AZLyrics.com. We start with pulling some information and analyzing them.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c8969e",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "185076b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "import re\n",
    "\n",
    "# for the lyrics scrape section\n",
    "import requests\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "from collections import defaultdict, Counter\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a47e2d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this cell for any import statements you add\n",
    "import shutil\n",
    "from bs4 import Comment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c13af3",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Lyrics Scrape\n",
    "\n",
    "This section asks you to pull data by scraping www.AZLyrics.com. In the notebooks where you do that work you are asked to store the data in specific ways. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5bd7df77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we'll use this dictionary to hold both the artist name and the link on AZlyrics\n",
    "# Added the two artists of my choosing\n",
    "artists = {'kelly':\"https://www.azlyrics.com/r/rowland.html\",\n",
    "           'usher':\"https://www.azlyrics.com/u/usher.html\"} "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c236c99b",
   "metadata": {},
   "source": [
    "## A Note on Rate Limiting\n",
    "\n",
    "The lyrics site, www.azlyrics.com, does not have an explicit maximum on number of requests in any one time, but in our testing it appears that too many requests in too short a time will cause the site to stop returning lyrics pages. (Entertainingly, the page that gets returned seems to only have the song title to [a Tom Jones song](https://www.azlyrics.com/lyrics/tomjones/itsnotunusual.html).) \n",
    "\n",
    "Whenever you call `requests.get` to retrieve a page, put a `time.sleep(5 + 10*random.random())` on the next line. This will help you not to get blocked. If you _do_ get blocked, which you can identify if the returned pages are not correct, just request a lyrics page through your browser. You'll be asked to perform a CAPTCHA and then your requests should start working again. \n",
    "\n",
    "## Part 1: Finding Links to Songs Lyrics\n",
    "\n",
    "That general artist page has a list of all songs for that artist with links to the individual song pages. \n",
    "\n",
    "Q: Take a look at the `robots.txt` page on www.azlyrics.com. (You can read more about these pages [here](https://developers.google.com/search/docs/advanced/robots/intro).) Is the scraping we are about to do allowed or disallowed by this page? How do you know? \n",
    "\n",
    "A: The robots.txt page on www.azlyrics.com states the following:\\\n",
    "`User-agent: * `\\\n",
    "`Disallow: /lyricsdb/ `\\\n",
    "`Disallow: /song/ `\\\n",
    "`Allow: /`\n",
    "\n",
    "`User-agent: 008 `\\\n",
    "`Disallow: / `\n",
    "\n",
    "The above means that for all users except user agent 008 (a specific user that AZLyrics has identified as potentially suspicious, a scammer, etc and is thus not allowed to scrape anything from the site) are not allowed to scrape from URLs that contain `/lyricsdb/` or `/song/`. However, users are permitted to scrape from all other pages on the website. We will be scraping from pages that begin with `www.azlyrics.com/<letter>/` (for the artist pages) and `www.azlyrics.com/lyrics/` (for the lyrics pages), so both should be allowed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9d31ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Cleared the output for this after running so PDF would not be super long)\n",
    "# Let's set up a dictionary of lists to hold our links\n",
    "lyrics_pages = defaultdict(list)\n",
    "\n",
    "for artist, artist_page in artists.items():\n",
    "    # request the page and sleep\n",
    "    r = requests.get(artist_page)\n",
    "    time.sleep(5 + 10*random.random())\n",
    "    \n",
    "    # Use BeautifulSoup to parse\n",
    "    artist_pg_soup = BeautifulSoup(r.text, 'html.parser')\n",
    "\n",
    "    # Investigated artist_pg_soup output in test code below to understand how lyrics page links are stored \n",
    "    # Extract all raw links\n",
    "    links_raw = artist_pg_soup.find_all('a', href=True)\n",
    "    \n",
    "    # Loop through links to format correctly & put in dict where the key is the artist and the\n",
    "        # value is a list of links\n",
    "    for link in links_raw:\n",
    "        href_raw = link['href']\n",
    "        # Check if lyric link\n",
    "        if \"/lyrics/\" in href_raw:\n",
    "            # Check if URL is full path\n",
    "            if href_raw.startswith('http'):\n",
    "                complete_link = href_raw\n",
    "            else: # Complete URL if not full path\n",
    "                complete_link = 'https://www.azlyrics.com' + href_raw\n",
    "            lyrics_pages[artist].append(complete_link)\n",
    "\n",
    "# Print dict to check\n",
    "lyrics_pages # Checked, then cleared output so not messy in PDF generated "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c285ec1",
   "metadata": {},
   "source": [
    "Let's make sure we have enough lyrics pages to scrape. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae4cda68",
   "metadata": {},
   "outputs": [],
   "source": [
    "for artist, lp in lyrics_pages.items() :\n",
    "    assert(len(set(lp)) > 20) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "edca10d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For kelly we have 105.\n",
      "The full pull will take for this artist will take 0.29 hours.\n",
      "For usher we have 225.\n",
      "The full pull will take for this artist will take 0.62 hours.\n"
     ]
    }
   ],
   "source": [
    "# Let's see how long it's going to take to pull these lyrics \n",
    "# if we're waiting `5 + 10*random.random()` seconds \n",
    "for artist, links in lyrics_pages.items() : \n",
    "    print(f\"For {artist} we have {len(links)}.\")\n",
    "    print(f\"The full pull will take for this artist will take {round(len(links)*10/3600,2)} hours.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011be6c6",
   "metadata": {},
   "source": [
    "## Part 2: Pulling Lyrics\n",
    "\n",
    "Now that we have the links to our lyrics pages, let's go scrape them! Here are the steps for this part. \n",
    "\n",
    "1. Create an empty folder in our repo called \"lyrics\". \n",
    "1. Iterate over the artists in `lyrics_pages`. \n",
    "1. Create a subfolder in lyrics with the artist's name. For instance, if the artist was Cher you'd have `lyrics/cher/` in your repo.\n",
    "1. Iterate over the pages. \n",
    "1. Request the page and extract the lyrics from the returned HTML file using BeautifulSoup.\n",
    "1. Use the function below, `generate_filename_from_link`, to create a filename based on the lyrics page, then write the lyrics to a text file with that name. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "67693711",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I made some changes to this definition to make it cleaner - explained in comments marked with my initials (SS)\n",
    "def generate_filename_from_link(link) :\n",
    "    if not link :\n",
    "        return None\n",
    "    \n",
    "    # drop the http or https and the html\n",
    "    # (SS) Added :// to what is being removed here so can later split on first /\n",
    "    name = link.replace(\"https://\",\"\").replace(\"http://\",\"\")  \n",
    "    name = name.replace(\".html\",\"\") # (SS) Fixed this - said \"link.replace\", should be \"name.replace\"\n",
    "\n",
    "    name = name.replace(\"www.azlyrics.com/lyrics/\",\"\") # (SS) Add the full URL before lyrics here to clean up more\n",
    "    \n",
    "    # (SS) Remove artist name since will already be in artist subfolder\n",
    "    name = name.split('/', 1)[1]\n",
    "    \n",
    "    # Replace useless chareacters with UNDERSCORE\n",
    "    name = name.replace(\".\",\"_\").replace(\"/\",\"_\")\n",
    "    \n",
    "    # tack on .txt\n",
    "    name = name + \".txt\"\n",
    "    \n",
    "    return(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "94a78c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the lyrics folder here. If you'd like to practice your programming, add functionality \n",
    "# that checks to see if the folder exists. If it does, then use shutil.rmtree to remove it and create a new one.\n",
    "\n",
    "# Turned into function so can also use to create artist subfolders\n",
    "def make_lyrics_folder(folder_name):\n",
    "    if folder_name != 'lyrics':\n",
    "        folder_name = 'lyrics/' + folder_name\n",
    "    if os.path.isdir(folder_name): \n",
    "        shutil.rmtree(folder_name)\n",
    "    os.mkdir(folder_name)\n",
    "    \n",
    "# Actually create lyrics folder\n",
    "make_lyrics_folder('lyrics')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "d655b687",
   "metadata": {},
   "outputs": [],
   "source": [
    "#url_stub = \"https://www.azlyrics.com\" - don't believe this is needed\n",
    "start = time.time()\n",
    "\n",
    "for artist in lyrics_pages:\n",
    "    # Move page counter to within this loop so resets for each artist, but not for each page within artist\n",
    "    total_pages = 0 \n",
    "\n",
    "    # Use this space to carry out the following steps: \n",
    "    \n",
    "    # 1. Build a subfolder for the artist\n",
    "    make_lyrics_folder(artist)\n",
    "    # 2. Iterate over the lyrics pages\n",
    "    for page in lyrics_pages.get(artist):\n",
    "        # 3. Request the lyrics page. \n",
    "        # Don't forget to add a line like `time.sleep(5 + 10*random.random())`\n",
    "        # to sleep after making the request\n",
    "        r = requests.get(page)\n",
    "        time.sleep(5 + 10*random.random())\n",
    "\n",
    "        # Use BeautifulSoup to parse\n",
    "        lyric_pg_soup = BeautifulSoup(r.text, 'html.parser')\n",
    "        \n",
    "        # 4. Extract the title \n",
    "        title_raw = lyric_pg_soup.find('h1')\n",
    "        title = title_raw.text.replace('\" lyrics', '').replace('\"', '').strip()\n",
    "        \n",
    "        # 4.5. Extract the lyrics\n",
    "        comment = lyric_pg_soup.find(string=lambda text: isinstance(text, Comment) and \n",
    "                                 \"Usage of azlyrics.com content by any third-party lyrics provider is prohibited\" in text)\n",
    "        # If the comment exists, get the parent div of the comment\n",
    "        if comment:\n",
    "            parent_div = comment.find_parent('div')  \n",
    "            # If parent div exists (error handling), get all text within it with some minor cleaning\n",
    "            if parent_div:\n",
    "                lyrics = []\n",
    "                for elem in parent_div.children:\n",
    "                    if elem.name == 'br':\n",
    "                        lyrics.append('\\n')\n",
    "                    elif isinstance(elem, str):\n",
    "                        lyrics.append(elem.strip())\n",
    "                lyrics = ''.join(lyrics).strip()\n",
    "        # Remove comment from output so just actual lyrics\n",
    "        lyrics = lyrics.replace(\"Usage of azlyrics.com content by any third-party lyrics provider is prohibited by our licensing agreement. Sorry about that.\", \"\")\n",
    "\n",
    "        # 5. Write out the title, two returns ('\\n'), and the lyrics. Use `generate_filename_from_link`\n",
    "        #    to generate the filename. \n",
    "        filename = generate_filename_from_link(page)\n",
    "        # Put within subfolder created for artist \n",
    "        with open(os.path.join('lyrics', artist, filename), 'w', encoding='utf-8') as file:\n",
    "            file.write(title + '\\n\\n' + lyrics)\n",
    "    \n",
    "        # Remember to pull at least 20 songs per artist. It may be fun to pull all the songs for the artist\n",
    "        total_pages += 1\n",
    "        # Break if total_pages == 20 to save time\n",
    "        if total_pages == 20: \n",
    "            break \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "36c394f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total run time was 0.12 hours.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total run time was {round((time.time() - start)/3600,2)} hours.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "054cf14b",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Evaluation\n",
    "\n",
    "This assignment asks you to pull data by scraping www.AZLyrics.com.  After you have finished the above sections , run all the cells in this notebook. Print this to PDF and submit it, per the instructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "217c2b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple word extractor from Peter Norvig: https://norvig.com/spell-correct.html\n",
    "def words(text): \n",
    "    return re.findall(r'\\w+', text.lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37778a1c",
   "metadata": {},
   "source": [
    "## Checking Lyrics \n",
    "\n",
    "The output from your lyrics scrape should be stored in files located in this path from the directory:\n",
    "`/lyrics/[Artist Name]/[filename from URL]`. This code summarizes the information at a high level to help the instructor evaluate your work. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "bccac29c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For kelly we have 20 files.\n",
      "For kelly we have roughly 9321 words, 1091 are unique.\n",
      "For usher we have 20 files.\n",
      "For usher we have roughly 9245 words, 763 are unique.\n"
     ]
    }
   ],
   "source": [
    "artist_folders = os.listdir(\"lyrics/\")\n",
    "artist_folders = [f for f in artist_folders if os.path.isdir(\"lyrics/\" + f)]\n",
    "\n",
    "for artist in artist_folders : \n",
    "    artist_files = os.listdir(\"lyrics/\" + artist)\n",
    "    artist_files = [f for f in artist_files if 'txt' in f or 'csv' in f or 'tsv' in f]\n",
    "\n",
    "    print(f\"For {artist} we have {len(artist_files)} files.\")\n",
    "\n",
    "    artist_words = []\n",
    "\n",
    "    for f_name in artist_files : \n",
    "        with open(\"lyrics/\" + artist + \"/\" + f_name) as infile : \n",
    "            artist_words.extend(words(infile.read()))\n",
    "\n",
    "            \n",
    "    print(f\"For {artist} we have roughly {len(artist_words)} words, {len(set(artist_words))} are unique.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "577f3ad1",
   "metadata": {},
   "source": [
    "## Test Code\n",
    "*Note:* I would not have this section in Production code, but I am leaving it in this assignment submission for the sake of showing my work/thought process for the above code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "36dd4be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Investigate full output from BeautifulSoup handling of artist page so know how to parse out links\n",
    "artist_pg_soup # output cleared so as not to make PDF very long\n",
    "\n",
    "# Output result: lyric links are stored such as <a href=\"/lyrics/usher/loveemall.html\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "145d0c99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'://usher/illmakeitright'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test code from within generate_filename_from_link function to see what intermediate outputs are\n",
    "link = \"https://www.azlyrics.com/lyrics/usher/illmakeitright.html\"\n",
    "name = link.replace(\"https\",\"\").replace(\"http\",\"\")\n",
    "name = name.replace(\".html\",\"\") # (SS) Fixed this - said \"link.replace\", should be \"name.replace\"\n",
    "\n",
    "name = name.replace(\"www.azlyrics.com/lyrics/\",\"\")\n",
    "name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4f2868f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'illmakeitright.txt'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test generate_filename_from_link function\n",
    "generate_filename_from_link(\"https://www.azlyrics.com/lyrics/usher/illmakeitright.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0df9ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test reading lyrics \n",
    "artist = 'kelly'\n",
    "artist_page = lyrics_pages.get(artist)[0]\n",
    "\n",
    "r = requests.get(artist_page)\n",
    "time.sleep(5 + 10*random.random())\n",
    "\n",
    "# Use BeautifulSoup to parse\n",
    "lyric_pg_soup = BeautifulSoup(r.text, 'html.parser')\n",
    "lyric_pg_soup # output cleared so not super long PDF "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8e4a71f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Stole'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract title test\n",
    "title_raw = lyric_pg_soup.find('h1')\n",
    "title = title_raw.text.replace('\" lyrics', '').replace('\"', '').strip()\n",
    "title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3914094e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract lyrics test - using Usage of azlyrics.com comment\n",
    "comment = lyric_pg_soup.find(string=lambda text: isinstance(text, Comment) and \n",
    "                                 \"Usage of azlyrics.com content by any third-party lyrics provider is prohibited\" in text)\n",
    "if comment:\n",
    "    parent_div = comment.find_parent('div')  # Get the parent div of the comment\n",
    "    if parent_div:\n",
    "        lyrics = []\n",
    "        for elem in parent_div.children:\n",
    "            if elem.name == 'br':\n",
    "                lyrics.append('\\n')\n",
    "            elif isinstance(elem, str):\n",
    "                lyrics.append(elem.strip())\n",
    "        lyrics = ''.join(lyrics).strip()\n",
    "        \n",
    "# Remove comment from output\n",
    "lyrics = lyrics.replace(\"Usage of azlyrics.com content by any third-party lyrics provider is prohibited by our licensing agreement. Sorry about that.\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "70b921d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"He was always such a nice boy\\nThe quiet one, with good intentions\\nHe was down for his brother, respectful to his mother\\nA good boy\\nBut good don't get attention\\nOne kid with a promise\\nThe brightest kid in school, he's not a fool\\nReadin' books about science and smart stuff\\nIt's not enough, no\\n'Cause smart don't make you cool, whoa\\n\\nHe's not invisible anymore\\nWith his Father's nine and a broken fuse\\nSince he walked through that classroom door\\nHe's all over prime-time news\\n\\nMary's got the same size hands\\nAs Marilyn Monroe\\nShe put her fingers in the imprints\\nAt Mann's Chinese Theater Show\\nShe could've been a movie star\\nNever got the chance to go that far\\nHer life was stole, oh\\nNow we'll never know\\n(No, no, no, no, oh)\\n\\nThey were cryin' to the camera, said he never fitted in\\nHe wasn't welcome\\nHe showed up to the parties we was hangin' in\\nSome guys were puttin' him down\\nBullyin' him 'round, round\\nNow I wish I would've talked to him\\nGave him the time of day and not turned away\\nIf I would've been the one to maybe go this far\\nHe might have stayed at home\\nPlayin' angry chords on his guitar\\n\\nHe's not invisible anymore\\nWith his baggy pants and his legs in chains\\nSince he walked through that classroom door\\nEverybody knows his name\\n\\nMary's got the same size hands (Oh)\\nAs Marilyn Monroe\\nShe put her fingers in the imprints (Ooh)\\nAt Mann's Chinese Theater Show (She could've been a movie star)\\nShe could've been a movie star (Oh-oh)\\nNever got the chance to go that far (Oh)\\nHer life was stole, oh\\nNow we'll never know (Now we'll never know, oh)\\n\\nGreg was always getting net from 20 feet away (20 feet away)\\nHe had a tryout with the Sixers, couldn't wait for Saturday (Saturday)\\nNow we're never gonna see him slam\\nFlyin' high as Kobe can\\nHis life was stole, oh\\nNow we'll never know (Now we'll never never never know)\\n\\nMm, now we'll never never never never know\\nStole, stole, stole\\nStole, stole, stole\\nOoh-oh, yeah yeah yeah yeah yeah, yeah\\n\\nMary's got the same size hands\\nAs Marilyn Monroe (Oh-oh)\\nShe put her fingers in the imprints\\nAt Mann's Chinese Theater Show (She was gonna be a star, oh no)\\nShe could've been a movie star\\nNever got the chance to go that far (Never got the chance, yeah)\\nHer life was stole, oh (Stole, stole)\\nOh, now we'll never know (Now we'll never never know, no)\\n\\nGreg was always getting net from 20 feet away (He had game, oh)\\nHe had a tryout with the Sixers, couldn't wait for Saturday\\nNow we're never gonna see him slam (Never see him)\\nFlyin' high as Kobe can\\nHis life was stole, oh\\nNow we'll never know (Now we'll never never know, no)\\n\\nOh, no no no\\nYeah, their lives were stole\\nNow we'll never know\\nWe were here all together, yesterday\""
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d764ee0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test writing to file\n",
    "make_lyrics_folder(artist)\n",
    "filename = generate_filename_from_link(artist_page)\n",
    "with open(os.path.join(artist, filename), 'w', encoding='utf-8') as file:\n",
    "    file.write(title + '\\n\\n' + lyrics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
